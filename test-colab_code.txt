# import kagglehub
# import os

# import numpy as np
# import pandas as pd

# from glob import glob
# import cv2
# from PIL import Image
# import matplotlib.pyplot as plt

# from sklearn.model_selection import train_test_split
# from sklearn.metrics import confusion_matrix, roc_auc_score

# import torch
# import torch.nn as nn
# from tqdm import tqdm
# import torchvision.models as models
# import torchvision
# from torch.utils.data import Dataset, DataLoader
# import albumentations as A
# from albumentations.pytorch import ToTensorV2

# # Download dataset
# path = kagglehub.dataset_download("kmader/skin-cancer-mnist-ham10000")
# print("Dataset path:", path)

# # show item in directory of downloaded data
# print(os.listdir(path))

# # Download metadata CSV
# csv_path = os.path.join(path, "HAM10000_metadata.csv")
# df = pd.read_csv(csv_path)

# # mapping label
# malignant = ["mel", "bcc", "akiec"]
# benign = ["nv", "bkl", "df", "vasc"]

# # change data types
# def map_label(dx):
#     if dx in malignant:
#         return 1   # malignant
#     else:
#         return 0   # benign

# # apply map_label
# df["label"] = df["dx"].apply(map_label)

# df[["dx", "label"]]

# # create image path dataframe
# dataset_dir = path

# imageid_path = {
#     os.path.splitext(os.path.basename(x))[0]: x
#     for x in glob(os.path.join(dataset_dir, '*', '*.jpg'))
# }

# df["image_path"] = df["image_id"].map(imageid_path)

# df[["image_id", "image_path"]].head()

# # Sample count by class
# class_counts = df['dx'].value_counts()

# class_counts_table = pd.DataFrame({
#     'Code': class_counts.index,
#     'Sample Count': class_counts.values,
#     'Ratio(%)': (class_counts.values / len(df) * 100).round(2),
#     'Type': ['Malignant' if x in malignant else 'Benign' for x in class_counts.index]
# })

# print("\n[Distribution by Class]")
# print(class_counts_table.to_string(index=False))

# # call data splitting function
# train_df, val_df, test_df = split_data_by_lesion_binary(
#     df,
#     test_size=0.15,
#     val_size=0.15,
#     random_state=42
# )

# # data augmentation
# def get_binary_dermatology_transforms(img_size=224):

#     train_transform = A.Compose([
#         # 1. Resize
#         A.Resize(img_size, img_size),

#         # 2. Geometric transforms
#         A.OneOf([
#             A.HorizontalFlip(p=1.0),
#             A.VerticalFlip(p=1.0),
#             A.Transpose(p=1.0),
#             A.RandomRotate90(p=1.0),
#         ], p=0.7),

#         A.ShiftScaleRotate(
#             shift_limit=0.0625,
#             scale_limit=0.1,
#             rotate_limit=45,
#             border_mode=cv2.BORDER_REFLECT,
#             p=0.5
#         ),

#         # 3. Advanced geometric (skin deformation simulation)
#         A.OneOf([
#             A.ElasticTransform(
#                 alpha=120,
#                 sigma=120 * 0.05,
#                 alpha_affine=120 * 0.03,
#                 border_mode=cv2.BORDER_REFLECT,
#                 p=1.0
#             ),
#             A.GridDistortion(
#                 num_steps=5,
#                 distort_limit=0.3,
#                 border_mode=cv2.BORDER_REFLECT,
#                 p=1.0
#             ),
#             A.OpticalDistortion(
#                 distort_limit=0.5,
#                 shift_limit=0.5,
#                 border_mode=cv2.BORDER_REFLECT,
#                 p=1.0
#             ),
#         ], p=0.4),

#         # 4. Color augmentations
#         A.OneOf([
#             A.RandomBrightnessContrast(
#                 brightness_limit=0.3,
#                 contrast_limit=0.3,
#                 p=1.0
#             ),
#             A.HueSaturationValue(
#                 hue_shift_limit=20,
#                 sat_shift_limit=30,
#                 val_shift_limit=20,
#                 p=1.0
#             ),
#             A.RGBShift(
#                 r_shift_limit=20,
#                 g_shift_limit=20,
#                 b_shift_limit=20,
#                 p=1.0
#             ),
#         ], p=0.7),

#         # 5. CLAHE - Important for lesion boundaries
#         A.CLAHE(
#             clip_limit=4.0,
#             tile_grid_size=(8, 8),
#             p=0.5
#         ),

#         # 6. Blur and noise
#         A.OneOf([
#             A.GaussianBlur(blur_limit=(3, 5), p=1.0),
#             A.MedianBlur(blur_limit=3, p=1.0),
#             A.MotionBlur(blur_limit=5, p=1.0),
#         ], p=0.3),

#         A.OneOf([
#             A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),
#             A.ISONoise(
#                 color_shift=(0.01, 0.05),
#                 intensity=(0.1, 0.5),
#                 p=1.0
#             ),
#         ], p=0.3),

#         # 7. Lighting effects
#         A.RandomShadow(
#             shadow_roi=(0, 0.5, 1, 1),
#             num_shadows_lower=1,
#             num_shadows_upper=2,
#             shadow_dimension=5,
#             p=0.2
#         ),

#         # 8. Coarse dropout (occlusion simulation)
#         A.CoarseDropout(
#             max_holes=8,
#             max_height=img_size // 10,
#             max_width=img_size // 10,
#             min_holes=1,
#             fill_value=0,
#             p=0.15
#         ),

#         # 9. Normalize (ImageNet stats)
#         A.Normalize(
#             mean=[0.485, 0.456, 0.406],
#             std=[0.229, 0.224, 0.225]
#         ),
#         ToTensorV2()
#     ])

#     # Validation/Test: Only resize + normalize
#     val_transform = A.Compose([
#         A.Resize(img_size, img_size),
#         A.Normalize(
#             mean=[0.485, 0.456, 0.406],
#             std=[0.229, 0.224, 0.225]
#         ),
#         ToTensorV2()
#     ])

#     return train_transform, val_transform


# train_transform, val_transform = get_binary_dermatology_transforms(img_size=224)

# # prepare data
# class HAM10000BinaryDataset(Dataset):

#     def __init__(self, df, img_dict, transform=None):
#         self.df = df.reset_index(drop=True)
#         self.img_dict = img_dict
#         self.transform = transform

#         # name of classes
#         self.class_names = {
#             0: "Benign",
#             1: "Malignant"
#         }

#     def __len__(self):
#         return len(self.df)

#     def __getitem__(self, idx):
#         # 1) import image_id and label (0/1) from df
#         img_id = self.df.loc[idx, 'image_id']
#         label = self.df.loc[idx, 'label']

#         # 2) find image path
#         img_path = self.img_dict.get(img_id)
#         if img_path is None:
#             raise FileNotFoundError(f"Image not found: {img_id}")

#         # 3) read images
#         image = cv2.imread(img_path)
#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

#         # 4) input Albumentations transform
#         if self.transform:
#             augmented = self.transform(image=image)
#             image = augmented['image']

#         # 5) output (image tensor, label 0/1)
#         return image, label

# train_dataset = HAM10000BinaryDataset(train_df, imageid_path, train_transform)
# val_dataset   = HAM10000BinaryDataset(val_df, imageid_path, val_transform)
# test_dataset  = HAM10000BinaryDataset(test_df, imageid_path, val_transform)

# print(f"Train dataset: {len(train_dataset)} samples")
# print(f"Val dataset:   {len(val_dataset)} samples")
# print(f"Test dataset:  {len(test_dataset)} samples")

# # count number in each class in Train set
# class_counts = train_df['label'].value_counts().sort_index()
# print(class_counts)

# # cal weights
# total = len(train_df)
# class_weights = total / (2 * class_counts)

# # chage to tensor
# class_weights_tensor = torch.tensor(class_weights.values, dtype=torch.float)

# print("\nClass Weights:")
# print(f"Class 0 (Benign):     {class_weights_tensor[0].item():.4f}")
# print(f"Class 1 (Malignant):  {class_weights_tensor[1].item():.4f}")

# # class weight function
# def compute_binary_class_weights(df, method='clip', **kwargs):

#     # count images
#     class_counts = df['label'].value_counts().sort_index()
#     total = len(df)
#     num_classes = len(class_counts)  # = 2

#     print("Class counts:")
#     print(class_counts)

#     # total / (C * count)
#     weights = total / (num_classes * class_counts.values)

#     # optimize weight
#     if method == 'clip':
#         c_min = kwargs.get('clip_min', 0.5)
#         c_max = kwargs.get('clip_max', 8.0)
#         weights_adjusted = np.clip(weights, c_min, c_max)
#         method_desc = f"Clipped to [{c_min}, {c_max}]"

#     elif method == 'sqrt':
#         weights_adjusted = np.sqrt(weights)
#         method_desc = "Square root transformation"

#     elif method == 'log':
#         weights_adjusted = np.log1p(weights)
#         method_desc = "Log transformation"

#     elif method == 'original':
#         weights_adjusted = weights
#         method_desc = "Original (no adjustment)"

#     else:
#         raise ValueError(f"Unsupported method: {method}")

#     # mean normalize
#     weights_normalized = weights_adjusted / weights_adjusted.mean()

#     print(f"\nApplied Method: {method_desc}")
#     print("\nClass Weights:")

#     for i in range(len(class_counts)):
#         print(f"Class {i}: count={class_counts.iloc[i]}, "
#               f"orig={weights[i]:.4f}, "
#               f"adj={weights_adjusted[i]:.4f}, "
#               f"norm={weights_normalized[i]:.4f}")

#     print("\n[Statistics]")
#     print(f"Original  - Min: {weights.min():.4f}, Max: {weights.max():.4f}, "
#           f"Range: {weights.max()/weights.min():.2f}x")
#     print(f"Adjusted  - Min: {weights_adjusted.min():.4f}, Max: {weights_adjusted.max():.4f}, "
#           f"Range: {weights_adjusted.max()/weights_adjusted.min():.2f}x")
#     print(f"Normalized - Min: {weights_normalized.min():.4f}, Max: {weights_normalized.max():.4f}, "
#           f"Range: {weights_normalized.max()/weights_normalized.min():.2f}x")

#     return torch.FloatTensor(weights_normalized)

# # result class weight
# device = "cuda" if torch.cuda.is_available() else "cpu"
# print(f"Using device: {device}")

# class_weights = compute_binary_class_weights(
#     train_df,
#     method='clip',
#     clip_max=5.0
# )

# class_weights = class_weights.to(device)

# criterion = nn.CrossEntropyLoss(weight=class_weights)

# # Hyperparameters
# BATCH_SIZE = 32
# NUM_WORKERS = 4

# # Create DataLoaders

# train_loader = DataLoader(
#     train_dataset,
#     batch_size=BATCH_SIZE,
#     shuffle=True,
#     num_workers=NUM_WORKERS,
#     pin_memory=True
# )

# val_loader = DataLoader(
#     val_dataset,
#     batch_size=BATCH_SIZE,
#     shuffle=False,
#     num_workers=NUM_WORKERS,
#     pin_memory=True
# )

# test_loader = DataLoader(
#     test_dataset,
#     batch_size=BATCH_SIZE,
#     shuffle=False,
#     num_workers=NUM_WORKERS,
#     pin_memory=True
# )

# print(f"Train loader: {len(train_loader)} batches")
# print(f"Val loader:   {len(val_loader)} batches")
# print(f"Test loader:  {len(test_loader)} batches")
# print(f"Batch size:   {BATCH_SIZE}")

# # Test loading one batch
# images, labels = next(iter(train_loader))
# print(images.shape)
# print(labels.shape)
# print(labels[:10])

# def visualize_augmentations_binary(dataset, num_samples=8,
#                                    save_path='augmented_samples_binary.png'):

#     fig, axes = plt.subplots(2, 4, figsize=(16, 8))
#     axes = axes.flatten()

#     # Denormalization parameters
#     mean = np.array([0.485, 0.456, 0.406])
#     std = np.array([0.229, 0.224, 0.225])

#     # map label
#     label_to_name = {
#         0: "Benign",
#         1: "Malignant"
#     }

#     for i in range(num_samples):
#         image, label = dataset[i]

#         # Convert tensor to numpy + denormalize
#         image_np = image.numpy().transpose(1, 2, 0)
#         image_np = std * image_np + mean
#         image_np = np.clip(image_np, 0, 1)

#         class_name = label_to_name[int(label)]

#         axes[i].imshow(image_np)
#         axes[i].set_title(f'{class_name} (label: {label})',
#                           fontsize=10, fontweight='bold')
#         axes[i].axis('off')

#     plt.suptitle(
#         'Binary Dermatology Augmentations\n'
#         'Geometric + Color + CLAHE + Noise + Distortion',
#         fontsize=14, fontweight='bold'
#     )

#     plt.tight_layout()
#     plt.savefig(save_path, dpi=150, bbox_inches='tight')
#     print(f"\nAugmented samples saved: {save_path}")
#     plt.show()


# # call function
# visualize_augmentations_binary(train_dataset, num_samples=8)

# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# # download model
# model = torchvision.models.resnet18(pretrained=True)

# # Binary
# model.fc = nn.Linear(model.fc.in_features, 2)

# model = model.to(device)

# criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))
# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# # training loop
# def train_one_epoch(model, dataloader, criterion, optimizer, device):
#     model.train()
#     running_loss = 0.0

#     for images, labels in tqdm(dataloader):
#         images = images.to(device)
#         labels = labels.to(device)

#         optimizer.zero_grad()

#         outputs = model(images)
#         loss = criterion(outputs, labels)

#         loss.backward()
#         optimizer.step()

#         running_loss += loss.item()

#     return running_loss / len(dataloader)

# # validation loop
# def validate_one_epoch(model, dataloader, criterion, device):
#     model.eval()
#     running_loss = 0.0
#     correct = 0
#     total = 0

#     with torch.no_grad():
#         for images, labels in dataloader:
#             images = images.to(device)
#             labels = labels.to(device)

#             outputs = model(images)
#             loss = criterion(outputs, labels)

#             running_loss += loss.item()

#             _, preds = torch.max(outputs, 1)
#             correct += (preds == labels).sum().item()
#             total += labels.size(0)

#     acc = correct / total
#     return running_loss / len(dataloader), acc

# EPOCHS = 5

# for epoch in range(EPOCHS):
#     train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)
#     val_loss, val_acc = validate_one_epoch(model, val_loader, criterion, device)

#     print(f"Epoch [{epoch+1}/{EPOCHS}]")
#     print(f"Train Loss: {train_loss:.4f}")
#     print(f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")

# # roc/auc & confution metrix
# model.eval()
# all_preds = []
# all_probs = []
# all_labels = []

# with torch.no_grad():
#     for images, labels in test_loader:
#         images = images.to(device)
#         outputs = model(images)
#         probs = torch.softmax(outputs, dim=1)[:, 1]
#         preds = torch.argmax(outputs, dim=1)

#         all_preds.extend(preds.cpu().numpy())
#         all_probs.extend(probs.cpu().numpy())
#         all_labels.extend(labels.numpy())

# auc = roc_auc_score(all_labels, all_probs)
# cm = confusion_matrix(all_labels, all_preds)

# print("AUC:", auc)
# print("Confusion Matrix:\n", cm)

# #ROC/AUC
# fpr, tpr, _ = roc_curve(y_test, y_pred_prob_rf)
# roc_auc = auc(fpr, tpr)

# plt.figure(figsize=(7, 6))
# plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.3f}")
# plt.plot([0, 1], [0, 1], linestyle="--")
# plt.xlabel("False Positive Rate")
# plt.ylabel("True Positive Rate")
# plt.title("ROC Curve")
# plt.legend()
# plt.show()

# # confusion metrix
# cm = confusion_matrix(y_test, y_pred_rf)

# plt.figure(figsize=(6, 6))
# plt.imshow(cm)
# plt.colorbar()

# plt.xticks([0,1], ["Benign (0)", "Malignant (1)"])
# plt.yticks([0,1], ["Benign (0)", "Malignant (1)"])

# plt.xlabel("Predicted Label")
# plt.ylabel("True Label")
# plt.title("Confusion Matrix")

# for i in range(2):
#     for j in range(2):
#         plt.text(j, i, cm[i, j], ha="center", va="center")

# plt.show()

# # save model
# torch.save(model.state_dict(), "resnet18_binary_skin.pth")
# print("Model saved!")